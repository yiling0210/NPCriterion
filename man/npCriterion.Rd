% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/npCriterion.R
\name{npCriterion}
\alias{npCriterion}
\title{Feature selection based on Neyman-Pearson Criterion (NPC)}
\usage{
npCriterion(x, y, method = c("logistic", "penlog", "svm", "randomforest",
  "lda", "slda", "nb", "nnb", "ada", "tree"), enumeration = NULL,
  max_feature_size = NULL, alpha, delta = 0.05, B = 5, l0 = 0.5,
  l1 = 0.5, seed = NULL, ncores = detectCores() - 1, ...)
}
\arguments{
\item{x}{a design matrix}

\item{y}{a vector containing binary labels 0 and 1}

\item{method}{base classification method
\itemize{
  \item logistic: Logistic regression. \code{\link[stats]{glm}} function with family = 'binomial'
  \item penlog: Penalized logistic regression with LASSO penalty. \code{\link[glmnet]{glmnet}} in glmnet package
  \item svm: Support Vector Machines. \code{\link[e1071]{svm}} in e1071 package
  \item randomforest: Random Forest. \code{\link[randomForest]{randomForest}} in randomForest package
  \item lda: Linear Discriminant Analysis. \code{\link[MASS]{lda}} in MASS package
  \item slda: Sparse Linear Discriminant Analysis with LASSO penalty.
  \item nb: Naive Bayes. \code{\link[e1071]{naiveBayes}} in e1071 package
  \item nnb: Nonparametric Naive Bayes. \code{\link[naivebayes]{naive_bayes}} in naivebayes package
  \item ada: Ada-Boost. \code{\link[ada]{ada}} in ada package
}}

\item{enumeration}{a feature set generation method, which can either be 'forward', 'backward' or 'exhaustive'. Default: 'forward'}

\item{max_feature_size}{an optional integer when enumeration is 'exhaustive'. When not supplied, set to be the total number of features}

\item{alpha}{a numeric scalar between 0 and 1 indicating the population type I error control}

\item{delta}{a numeric scalar between 0 and 1 indicating the violation rate. Default: 0.05}

\item{B}{a positive integer indicating the number of random splits. Default: 5}

\item{l0}{a numeric scalar between 0 and 1 indicating the proportion of leave-out class 0 data points. Default: 0.5}

\item{l1}{a numeric scalar between 0 and 1 indicating the proportion of leave-out class 1 data points. Default: 0.5}

\item{seed}{random seed}

\item{ncores}{a positive integer that specifies the number of cores for computing. Default: number of cores - 1.}

\item{...}{additional argument for base classification methods.}
}
\value{
\code{npCriterion} returns a list with the following components:

\item{method}{the base classification method}
\item{alpha}{user-specified alpha value}
\item{delta}{user-specified delta value}
\item{B}{total number of random splits}
\item{l0}{the proportion of leave-out class 0 data points}
\item{l1}{the proportion of leave-out class 1 data points}
\item{featuresets_examined}{when 'enumeration' = 'forward', a list of size 2 whose first component is enumeration, and the second component is a vector of the features that are sequentially included;
when 'enumeration' = 'backward', a list of size 2 whose first component is enumeration, and the second component is a vector of the features that are sequentially excluded;
when 'enumeration' = 'exhaustive', a list of size 2 whose first component is enumeration, and the second component is a list of matrices whose column number ranges from 1 to max_feature_size. Rows of such a matrix represent a feature set.
}
\item{npc}{when 'enumeration' = 'forward' or 'backward', a vector of NPC values of feature sets in featuresets_examined;
when 'enumeration' = 'exhaustive', a list of vectors of NPC values computed on the feature sets in featuresets_examined
}
\item{npc.sd}{when 'enumeration' = 'forward' or 'backward', a vector of standard deviations of empirical type II errors of feature sets in featuresets_examined;
when 'enumeration' = 'exhaustive', a list of standard deviations of empirical type II errors computed on the feature sets in featuresets_examined
}
\item{npc.se}{when 'enumeration' = 'forward' or 'backward', a vector of standard errors of empirical type II errors of feature sets in featuresets_examined;
when 'enumeration' = 'exhaustive', a list of standard errors of empirical type II errors computed on the feature sets in featuresets_examined
}
\item{err}{when 'enumeration' = 'forward' or 'backward', a vector of CV errors of feature sets in featuresets_examined;
when 'enumeration' = 'exhaustive', a list of vectors of CV errors computed on the feature sets in featuresets_examined
}
\item{err.se}{when 'enumeration' = 'forward' or 'backward', a vector of standard deviations of test errors of feature sets in featuresets_examined;
when 'enumeration' = 'exhaustive', a list of standard deviations of test errors computed on the feature sets in featuresets_examined
}
\item{err.se}{when 'enumeration' = 'forward' or 'backward', a vector of standard errors of test errors of feature sets in featuresets_examined;
when 'enumeration' = 'exhaustive', a list of standard errors of test errors computed on the feature sets in featuresets_examined
}
\item{features_minNPC}{a feature set with the minimal NPC value and its corresponding NPC statistics and test errors.}
}
\description{
Feature selection based on Neyman-Pearson Criterion (NPC)
}
\examples{
### Example1 #####
x = matrix(rnorm(20000), ncol =5)
y = rbinom(x\%*\%1:5,size = 1, p =0.5)
table(y)
temp1 = npCriterion(x,y,method = "logistic",
enumeration = 'forward',
max_feature_size = NULL,
alpha =  0.05,
delta = 0.05,
B = 5,
l0 = 0.5,
l1 = 0.5)

temp2 = npCriterion(x,y,method ="svm",
kernel = 'radial',
enumeration = 'exhaustive',
alpha =  0.05,
delta = 0.05,
B = 5,
l0 = 0.5,
l1 = 0.5)
### Example2 #####
y = rbinom(100000,size = 1, p =0.5)
x = matrix(NA, nrow =100000,ncol =2)
x1 = cbind(rnorm(sum(y==1),mean =1, sd =1),rnorm(sum(y==1),mean =1, sd =1))
x0 = cbind(rnorm(sum(y==0),mean =-1, sd =1),rnorm(sum(y==0),mean =0.5, sd =1.5))
pnorm(qnorm(0.95,-1,1),1,1)
pnorm(qnorm(0.95,0.5,1.5),1,1)
x[y==1,] = x1
x[y==0,] = x0
table(y)

temp3 = npCriterion(x,y,method ="lda",
                    enumeration = 'exhaustive',
                    alpha =  0.05,
                    delta = 0.05,
                    B = 5,
                    l0 = 0.5,
                    l1 = 0.5)
temp3$criteria$`ell=1`


}
\references{
\bold{FILL HERE}
}
\author{
Yiling Chen, \email{yiling0210@ucla.edu}
}
